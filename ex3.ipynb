{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frequent Itemsets:\n",
      "{'milk'}: 4\n",
      "{'bread'}: 5\n",
      "{'butter'}: 4\n",
      "{'milk', 'bread'}: 3\n",
      "{'butter', 'bread'}: 3\n",
      "{'milk', 'butter'}: 3\n"
     ]
    }
   ],
   "source": [
    "def generate_candidates(freq_itemsets, k):\n",
    "    # Initialize an empty set to store candidate itemsets of length k\n",
    "    candidates = set()\n",
    "\n",
    "    # Iterate over each pair of itemsets in the list of frequent itemsets\n",
    "    for i in range(len(freq_itemsets)):\n",
    "        for j in range(i + 1, len(freq_itemsets)):\n",
    "            # Extract the first k-2 items from both itemsets\n",
    "            l1 = list(freq_itemsets[i])[:k-2]\n",
    "            l2 = list(freq_itemsets[j])[:k-2]\n",
    "\n",
    "            # If the first k-2 items of both itemsets are the same, merge them\n",
    "            if l1 == l2:\n",
    "                # Create a candidate itemset by combining the two itemsets\n",
    "                candidate = frozenset(freq_itemsets[i]) | frozenset(freq_itemsets[j])\n",
    "                \n",
    "                # Add the candidate itemset to the set of candidates\n",
    "                candidates.add(candidate)\n",
    "\n",
    "    return candidates\n",
    "\n",
    "def scan_dataset(dataset, candidates):\n",
    "    # Initialize a dictionary to count occurrences of each candidate itemset\n",
    "    itemset_counts = {itemset: 0 for itemset in candidates}\n",
    "\n",
    "    # Iterate over each transaction in the dataset\n",
    "    for transaction in dataset:\n",
    "        # Check each candidate itemset\n",
    "        for candidate in candidates:\n",
    "            # If the candidate itemset is a subset of the transaction, count it\n",
    "            if candidate.issubset(transaction):\n",
    "                itemset_counts[candidate] += 1\n",
    "\n",
    "    return itemset_counts\n",
    "\n",
    "def filter_itemsets(itemset_counts, min_support, total_transactions):\n",
    "    # Filter itemsets based on minimum support threshold\n",
    "    return {itemset: count for itemset, count in itemset_counts.items() if count / total_transactions >= min_support}\n",
    "\n",
    "def apriori(dataset, min_support):\n",
    "    # Initialize a dictionary to store frequent itemsets\n",
    "    freq_itemsets = {}\n",
    "\n",
    "    # Generate a set of single-item itemsets\n",
    "    one_itemsets = {frozenset([item]) for transaction in dataset for item in transaction}\n",
    "    \n",
    "    # Scan the dataset for itemset counts\n",
    "    itemset_counts = scan_dataset(dataset, one_itemsets)\n",
    "    total_transactions = len(dataset)\n",
    "    \n",
    "    # Filter itemsets based on minimum support and update the frequent itemsets\n",
    "    freq_itemsets.update(filter_itemsets(itemset_counts, min_support, total_transactions))\n",
    "    \n",
    "    # Initialize the list of frequent itemsets of length k\n",
    "    freq_itemsets_list = [itemset for itemset in freq_itemsets.keys()]\n",
    "    \n",
    "    # Start with itemsets of length 2 and increment k\n",
    "    k = 2\n",
    "    while freq_itemsets_list:\n",
    "        # Generate candidate itemsets of length k\n",
    "        candidates = generate_candidates(freq_itemsets_list, k)\n",
    "        \n",
    "        # Break the loop if no candidates are generated\n",
    "        if not candidates:\n",
    "            break\n",
    "        \n",
    "        # Scan the dataset for counts of candidate itemsets\n",
    "        itemset_counts = scan_dataset(dataset, candidates)\n",
    "        \n",
    "        # Filter itemsets based on minimum support and update the frequent itemsets\n",
    "        freq_itemsets.update(filter_itemsets(itemset_counts, min_support, total_transactions))\n",
    "        \n",
    "        # Update the list of frequent itemsets of length k\n",
    "        freq_itemsets_list = [itemset for itemset in freq_itemsets.keys() if len(itemset) == k]\n",
    "        \n",
    "        # Increment k to process itemsets of length k+1\n",
    "        k += 1\n",
    "    \n",
    "    return freq_itemsets\n",
    "\n",
    "def main():\n",
    "    # Sample dataset: each transaction is represented as a set of items\n",
    "    dataset = [\n",
    "        {'milk', 'bread', 'butter'},\n",
    "        {'milk', 'bread'},\n",
    "        {'milk', 'butter'},\n",
    "        {'bread', 'butter'},\n",
    "        {'milk', 'bread', 'butter', 'eggs'},\n",
    "        {'bread', 'eggs'}\n",
    "    ]\n",
    "    \n",
    "    # Set the minimum support threshold\n",
    "    min_support = 0.5\n",
    "    \n",
    "    # Run the Apriori algorithm to find frequent itemsets\n",
    "    freq_itemsets = apriori(dataset, min_support)\n",
    "    \n",
    "    # Print the frequent itemsets and their counts\n",
    "    print(\"Frequent Itemsets:\")\n",
    "    for itemset, count in freq_itemsets.items():\n",
    "        print(f\"{set(itemset)}: {count}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
